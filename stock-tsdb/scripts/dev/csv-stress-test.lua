#!/usr/bin/env luajit

-- CSVå¯¼å…¥å¯¼å‡ºå‹åŠ›æµ‹è¯•è„šæœ¬
-- é’ˆå¯¹Stock-TSDBç³»ç»Ÿçš„CSVæ•°æ®å¯¼å…¥å¯¼å‡ºåŠŸèƒ½è¿›è¡Œé«˜å¹¶å‘å‹åŠ›æµ‹è¯•

-- åŠ è½½å¿…è¦çš„æ¨¡å—
local json = {
    encode = function(t) 
        if type(t) ~= 'table' then return tostring(t) end
        local parts = {}
        for k, v in pairs(t) do
            table.insert(parts, '"' .. tostring(k) .. '":' .. (type(v) == 'string' and '"' .. v .. '"' or tostring(v)))
        end
        return "{" .. table.concat(parts, ",") .. "}"
    end,
    decode = function(s) 
        -- ç®€å•çš„JSONè§£æå™¨
        local result = {}
        -- è¿™é‡Œåº”è¯¥å®ç°å®Œæ•´çš„JSONè§£æï¼Œç°åœ¨ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬
        return result
    end
}
local ffi = require "ffi"

-- ç®€åŒ–çš„HTTPå®¢æˆ·ç«¯å®ç°ï¼ˆåŸºäºlibcurl FFIï¼‰
local function create_simple_http_client()
    -- å®šä¹‰libcurl FFIæ¥å£
    ffi.cdef[[
        typedef void CURL;
        typedef int CURLcode;
        
        CURL* curl_easy_init(void);
        CURLcode curl_easy_setopt(CURL* curl, int option, ...);
        CURLcode curl_easy_perform(CURL* curl);
        void curl_easy_cleanup(CURL* curl);
        char* curl_easy_strerror(CURLcode);
        
        typedef size_t (*curl_write_callback)(char* ptr, size_t size, size_t nmemb, void* userdata);
        
        CURLcode curl_global_init(long flags);
        void curl_global_cleanup(void);
    ]]
    
    -- å°è¯•åŠ è½½libcurl
    local curl_lib = nil
    for _, lib_name in ipairs({"curl", "libcurl", "libcurl.so.4", "libcurl.dylib"}) do
        local ok, lib = pcall(ffi.load, lib_name)
        if ok then
            curl_lib = lib
            break
        end
    end
    
    if not curl_lib then
        return nil, "libcurlä¸å¯ç”¨"
    end
    
    -- åˆå§‹åŒ–libcurl
    local ret = curl_lib.curl_global_init(0)
    if ret ~= 0 then
        return nil, "libcurlå…¨å±€åˆå§‹åŒ–å¤±è´¥"
    end
    
    return {
        curl_lib = curl_lib,
        request = function(self, url, method, data, headers)
            local curl = self.curl_lib.curl_easy_init()
            if curl == nil then
                return false, nil, "æ— æ³•åˆ›å»ºCURLå¥æŸ„"
            end
            
            -- ç®€å•çš„å“åº”æ”¶é›†
            local response_data = {}
            local response_code = 0
            
            -- å†™å…¥å›è°ƒ
            local function write_callback(ptr, size, nmemb, userdata)
                local total_size = size * nmemb
                local data = ffi.string(ptr, total_size)
                table.insert(response_data, data)
                return total_size
            end
            
            -- é‡ç”¨å›è°ƒæŒ‡é’ˆä»¥é¿å…too many callbacksé”™è¯¯
            if not self.callback_ptr then
                self.callback_ptr = ffi.cast("curl_write_callback", write_callback)
            end
            local callback_ptr = self.callback_ptr
            
            -- è®¾ç½®åŸºæœ¬é€‰é¡¹
            self.curl_lib.curl_easy_setopt(curl, 10002, url)  -- CURLOPT_URL
            self.curl_lib.curl_easy_setopt(curl, 20011, callback_ptr)  -- CURLOPT_WRITEFUNCTION
            
            -- æ‰§è¡Œè¯·æ±‚
            local ret = self.curl_lib.curl_easy_perform(curl)
            
            if ret == 0 then
                local response = table.concat(response_data)
                curl_lib.curl_easy_cleanup(curl)
                return true, response, nil
            else
                local error_msg = "HTTPè¯·æ±‚å¤±è´¥"
                curl_lib.curl_easy_cleanup(curl)
                return false, nil, error_msg
            end
        end,
        cleanup = function(self)
            self.curl_lib.curl_global_cleanup()
        end
    }
end

-- åˆ›å»ºHTTPå®¢æˆ·ç«¯
local curl_ok, curl_client = pcall(create_simple_http_client)
if curl_ok and curl_client then
    http_client = curl_client
    print("âœ… ä½¿ç”¨libcurl HTTPå®¢æˆ·ç«¯")
else
    -- å¦‚æœlibcurlä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼
    print("âš ï¸  libcurlä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
    print("é”™è¯¯ä¿¡æ¯: " .. tostring(curl_client))
    http_client = {
        request = function(self, url, method, data, headers)
            -- æ¨¡æ‹ŸHTTPè¯·æ±‚
            if url:find("/health") then
                return true, '{"status":"ok"}', nil
            elseif url:find("/csv/import") then
                return true, '{"success":true,"rows_processed":100}', nil
            elseif url:find("/csv/export") then
                return true, '{"success":true,"rows":100,"data":"time,value\\n1,100\\n2,200"}', nil
            else
                return false, nil, "æœªçŸ¥ç«¯ç‚¹"
            end
        end
    }
end

-- å‹åŠ›æµ‹è¯•é…ç½®
local config = {
    -- åŸºç¡€é…ç½®
    base_url = "http://localhost:8081",
    
    -- å¹¶å‘é…ç½®
    concurrent_threads = 5,           -- å¹¶å‘çº¿ç¨‹æ•°
    requests_per_thread = 100,        -- æ¯ä¸ªçº¿ç¨‹è¯·æ±‚æ•°
    
    -- CSVæ•°æ®é…ç½®
    business_types = {
        "stock_quotes",
        "iot_data", 
        "financial_quotes",
        "orders",
        "payments"
    },
    
    -- æ•°æ®é‡é…ç½®
    csv_rows_per_request = 1000,      -- æ¯ä¸ªCSVè¯·æ±‚çš„æ•°æ®è¡Œæ•°
    csv_file_size_mb = 10,            -- ç”Ÿæˆçš„CSVæ–‡ä»¶å¤§å°ï¼ˆMBï¼‰
    
    -- æ—¶é—´é…ç½®
    test_duration = 300,              -- æµ‹è¯•æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
    warmup_duration = 30,             -- é¢„çƒ­æ—¶é—´ï¼ˆç§’ï¼‰
    
    -- æ€§èƒ½é˜ˆå€¼
    max_latency_p99 = 5000,           -- P99å»¶è¿Ÿé˜ˆå€¼ï¼ˆæ¯«ç§’ï¼‰
    min_throughput = 100,             -- æœ€å°ååé‡ï¼ˆè¯·æ±‚/ç§’ï¼‰
    max_error_rate = 0.05             -- æœ€å¤§é”™è¯¯ç‡
}

-- æµ‹è¯•ç»“æœç»Ÿè®¡
local test_results = {
    total_requests = 0,
    successful_requests = 0,
    failed_requests = 0,
    total_latency = 0,
    latencies = {},
    start_time = 0,
    end_time = 0,
    csv_import_stats = {},
    csv_export_stats = {}
}

-- HTTPè¯·æ±‚å‡½æ•°ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
local function http_request(method, url, data, headers)
    local max_retries = 3
    local retry_delay = 0.1  -- 100ms
    
    for attempt = 1, max_retries do
        local success, response, error_msg = http_client:request(url, method, data, headers)
        
        if success and response then
            return 200, response  -- å‡è®¾æˆåŠŸçŠ¶æ€ç ä¸º200
        end
        
        -- è¯·æ±‚å¤±è´¥ï¼Œå‡†å¤‡é‡è¯•
        if attempt < max_retries then
            -- ç®€å•çš„å»¶è¿Ÿå®ç°
            local start_time = os.clock()
            while os.clock() - start_time < retry_delay do
                -- å¿™ç­‰å¾…
            end
            retry_delay = retry_delay * 2  -- æŒ‡æ•°é€€é¿
        end
    end
    
    return nil, "è¯·æ±‚å¤±è´¥ï¼ˆé‡è¯•3æ¬¡åï¼‰"
end

-- ç”Ÿæˆæµ‹è¯•CSVæ•°æ®
local function generate_csv_data(business_type, row_count)
    local csv_content = ""
    local headers = {}
    
    -- æ ¹æ®ä¸šåŠ¡ç±»å‹ç”Ÿæˆä¸åŒçš„CSVæ•°æ®
    if business_type == "stock_quotes" then
        headers = {"timestamp", "stock_code", "market", "open", "high", "low", "close", "volume", "amount"}
        csv_content = table.concat(headers, ",") .. "\n"
        
        for i = 1, row_count do
            local timestamp = os.time() * 1000000 + i * 1000
            local stock_code = string.format("%06d", math.random(1, 999999))
            local market = math.random(0, 1) == 0 and "SH" or "SZ"
            local open = math.random(1000, 50000) / 100
            local high = open * (1 + math.random() * 0.1)
            local low = open * (1 - math.random() * 0.05)
            local close = math.random(low * 100, high * 100) / 100
            local volume = math.random(1000, 1000000)
            local amount = volume * close
            
            csv_content = csv_content .. string.format("%d,%s,%s,%.2f,%.2f,%.2f,%.2f,%d,%.2f\n", 
                timestamp, stock_code, market, open, high, low, close, volume, amount)
        end
        
    elseif business_type == "iot_data" then
        headers = {"timestamp", "device_id", "sensor_type", "value", "unit", "location", "status"}
        csv_content = table.concat(headers, ",") .. "\n"
        
        for i = 1, row_count do
            local timestamp = os.time() * 1000000 + i * 1000
            local device_id = "device-" .. string.format("%03d", math.random(1, 100))
            local sensor_types = {"temperature", "humidity", "pressure", "voltage", "current"}
            local sensor_type = sensor_types[math.random(1, #sensor_types)]
            local value = math.random(0, 1000) / 10
            local unit = sensor_type == "temperature" and "C" or sensor_type == "humidity" and "%" or ""
            local location = "room-" .. string.format("%03d", math.random(1, 50))
            local status = "normal"
            
            csv_content = csv_content .. string.format("%d,%s,%s,%.1f,%s,%s,%s\n", 
                timestamp, device_id, sensor_type, value, unit, location, status)
        end
        
    elseif business_type == "financial_quotes" then
        headers = {"timestamp", "symbol", "exchange", "bid", "ask", "last_price", "volume", "change", "change_percent"}
        csv_content = table.concat(headers, ",") .. "\n"
        
        for i = 1, row_count do
            local timestamp = os.time() * 1000000 + i * 1000
            local symbol = "EUR/USD"
            local exchange = "FOREX"
            local bid = 1.1000 + math.random() * 0.01
            local ask = bid + 0.0005
            local last_price = (bid + ask) / 2
            local volume = math.random(1000000, 10000000)
            local change = math.random(-50, 50) / 1000
            local change_percent = change / last_price * 100
            
            csv_content = csv_content .. string.format("%d,%s,%s,%.4f,%.4f,%.4f,%d,%.4f,%.2f\n", 
                timestamp, symbol, exchange, bid, ask, last_price, volume, change, change_percent)
        end
        
    elseif business_type == "orders" then
        headers = {"timestamp", "order_id", "user_id", "product_id", "quantity", "price", "status", "payment_method"}
        csv_content = table.concat(headers, ",") .. "\n"
        
        for i = 1, row_count do
            local timestamp = os.time() * 1000000 + i * 1000
            local order_id = "order-" .. string.format("%08d", math.random(1, 99999999))
            local user_id = "user-" .. string.format("%06d", math.random(1, 999999))
            local product_id = "product-" .. string.format("%04d", math.random(1, 9999))
            local quantity = math.random(1, 10)
            local price = math.random(100, 10000) / 100
            local statuses = {"pending", "confirmed", "shipped", "delivered", "cancelled"}
            local status = statuses[math.random(1, #statuses)]
            local payment_methods = {"credit_card", "paypal", "alipay", "wechat_pay"}
            local payment_method = payment_methods[math.random(1, #payment_methods)]
            
            csv_content = csv_content .. string.format("%d,%s,%s,%s,%d,%.2f,%s,%s\n", 
                timestamp, order_id, user_id, product_id, quantity, price, status, payment_method)
        end
        
    elseif business_type == "payments" then
        headers = {"timestamp", "payment_id", "order_id", "amount", "currency", "status", "payment_gateway", "user_id"}
        csv_content = table.concat(headers, ",") .. "\n"
        
        for i = 1, row_count do
            local timestamp = os.time() * 1000000 + i * 1000
            local payment_id = "payment-" .. string.format("%08d", math.random(1, 99999999))
            local order_id = "order-" .. string.format("%08d", math.random(1, 99999999))
            local amount = math.random(100, 10000) / 100
            local currency = "USD"
            local statuses = {"pending", "processing", "completed", "failed", "refunded"}
            local status = statuses[math.random(1, #statuses)]
            local payment_gateways = {"stripe", "paypal", "square", "adyen"}
            local payment_gateway = payment_gateways[math.random(1, #payment_gateways)]
            local user_id = "user-" .. string.format("%06d", math.random(1, 999999))
            
            csv_content = csv_content .. string.format("%d,%s,%s,%.2f,%s,%s,%s,%s\n", 
                timestamp, payment_id, order_id, amount, currency, status, payment_gateway, user_id)
        end
    end
    
    return csv_content
end

-- åˆ›å»ºä¸´æ—¶CSVæ–‡ä»¶
local function create_temp_csv_file(business_type, row_count)
    local filename = "/tmp/csv_stress_test_" .. business_type .. "_" .. os.time() .. ".csv"
    local csv_content = generate_csv_data(business_type, row_count)
    
    local file = io.open(filename, "w")
    if file then
        file:write(csv_content)
        file:close()
        return filename
    else
        return nil
    end
end

-- CSVå¯¼å…¥å‹åŠ›æµ‹è¯•
local function csv_import_stress_test(thread_id)
    local thread_results = {
        requests = 0,
        successes = 0,
        failures = 0,
        total_latency = 0,
        imported_rows = 0
    }
    
    for i = 1, config.requests_per_thread do
        local business_type = config.business_types[math.random(1, #config.business_types)]
        local csv_filename = create_temp_csv_file(business_type, config.csv_rows_per_request)
        
        if csv_filename then
            -- æ„å»ºCSVå¯¼å…¥è¯·æ±‚
            local request_data = {
                file_path = csv_filename,
                business_type = business_type,
                options = {
                    batch_size = 100,
                    validate_format = true
                }
            }
            
            local start_time = os.clock() * 1000  -- æ¯«ç§’
            local status, response = http_request("POST", 
                config.base_url .. "/csv/import", 
                json.encode(request_data))
            local end_time = os.clock() * 1000
            local latency = end_time - start_time
            
            thread_results.requests = thread_results.requests + 1
            thread_results.total_latency = thread_results.total_latency + latency
            
            if status == 200 then
                thread_results.successes = thread_results.successes + 1
                local result = json.decode(response)
                if result and result.imported_count then
                    thread_results.imported_rows = thread_results.imported_rows + result.imported_count
                end
            else
                thread_results.failures = thread_results.failures + 1
                print(string.format("Thread %d: CSVå¯¼å…¥å¤±è´¥ - Status: %d, Response: %s", 
                    thread_id, status, response))
            end
            
            -- æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            os.remove(csv_filename)
            
            -- æ¯10ä¸ªè¯·æ±‚è¾“å‡ºä¸€æ¬¡è¿›åº¦
            if i % 10 == 0 then
                print(string.format("Thread %d: CSVå¯¼å…¥è¿›åº¦ %d/%d (%.1f%%)", 
                    thread_id, i, config.requests_per_thread, i/config.requests_per_thread*100))
            end
            
            -- æ·»åŠ éšæœºå»¶è¿Ÿæ¨¡æ‹ŸçœŸå®è´Ÿè½½
            if math.random() < 0.2 then  -- 20%çš„æ¦‚ç‡æ·»åŠ å»¶è¿Ÿ
                socket.sleep(math.random() * 0.1)  -- 0-100æ¯«ç§’å»¶è¿Ÿ
            end
        else
            thread_results.failures = thread_results.failures + 1
            print(string.format("Thread %d: åˆ›å»ºCSVæ–‡ä»¶å¤±è´¥", thread_id))
        end
    end
    
    return thread_results
end

-- CSVå¯¼å‡ºå‹åŠ›æµ‹è¯•
local function csv_export_stress_test(thread_id)
    local thread_results = {
        requests = 0,
        successes = 0,
        failures = 0,
        total_latency = 0,
        exported_rows = 0
    }
    
    for i = 1, config.requests_per_thread do
        local business_type = config.business_types[math.random(1, #config.business_types)]
        local export_filename = "/tmp/csv_export_" .. business_type .. "_" .. os.time() .. "_" .. thread_id .. ".csv"
        
        -- æ„å»ºCSVå¯¼å‡ºè¯·æ±‚
        local end_time = os.time() * 1000000
        local start_time = end_time - 3600 * 1000000  -- å¯¼å‡ºæœ€è¿‘1å°æ—¶æ•°æ®
        
        local request_data = {
            file_path = export_filename,
            business_type = business_type,
            start_time = start_time,
            end_time = end_time,
            filters = {}
        }
        
        local start_time_ms = os.clock() * 1000
            local status, response = http_request("POST", 
                config.base_url .. "/csv/export", 
                json.encode(request_data))
            local end_time_ms = os.clock() * 1000
        local latency = end_time_ms - start_time_ms
        
        thread_results.requests = thread_results.requests + 1
        thread_results.total_latency = thread_results.total_latency + latency
        
        if status == 200 then
            thread_results.successes = thread_results.successes + 1
            local result = json.decode(response)
            if result and result.exported_count then
                thread_results.exported_rows = thread_results.exported_rows + result.exported_count
            end
            
            -- éªŒè¯å¯¼å‡ºçš„æ–‡ä»¶
            local export_file = io.open(export_filename, "r")
            if export_file then
                local content = export_file:read("*all")
                export_file:close()
                -- å¯ä»¥æ·»åŠ æ–‡ä»¶å†…å®¹éªŒè¯é€»è¾‘
            end
            
            -- æ¸…ç†å¯¼å‡ºçš„æ–‡ä»¶
            os.remove(export_filename)
        else
            thread_results.failures = thread_results.failures + 1
            print(string.format("Thread %d: CSVå¯¼å‡ºå¤±è´¥ - Status: %d, Response: %s", 
                thread_id, status, response))
        end
        
        -- æ¯10ä¸ªè¯·æ±‚è¾“å‡ºä¸€æ¬¡è¿›åº¦
        if i % 10 == 0 then
            print(string.format("Thread %d: CSVå¯¼å‡ºè¿›åº¦ %d/%d (%.1f%%)", 
                thread_id, i, config.requests_per_thread, i/config.requests_per_thread*100))
        end
        
        -- æ·»åŠ éšæœºå»¶è¿Ÿæ¨¡æ‹ŸçœŸå®è´Ÿè½½
        if math.random() < 0.3 then  -- 30%çš„æ¦‚ç‡æ·»åŠ å»¶è¿Ÿ
            socket.sleep(math.random() * 0.05)  -- 0-50æ¯«ç§’å»¶è¿Ÿ
        end
    end
    
    return thread_results
end

-- æ··åˆå‹åŠ›æµ‹è¯•ï¼ˆåŒæ—¶è¿›è¡Œå¯¼å…¥å’Œå¯¼å‡ºï¼‰
local function mixed_stress_test(thread_id)
    local thread_results = {
        import_requests = 0,
        export_requests = 0,
        import_successes = 0,
        export_successes = 0,
        import_failures = 0,
        export_failures = 0,
        total_latency = 0,
        imported_rows = 0,
        exported_rows = 0
    }
    
    for i = 1, config.requests_per_thread do
        -- éšæœºé€‰æ‹©å¯¼å…¥æˆ–å¯¼å‡ºæ“ä½œ
        local is_import = math.random() < 0.6  -- 60%çš„æ¦‚ç‡è¿›è¡Œå¯¼å…¥
        
        if is_import then
            local business_type = config.business_types[math.random(1, #config.business_types)]
            local csv_filename = create_temp_csv_file(business_type, config.csv_rows_per_request)
            
            if csv_filename then
                local request_data = {
                    file_path = csv_filename,
                    business_type = business_type,
                    options = {batch_size = 100}
                }
                
                local start_time = os.clock() * 1000
                local status, response = http_request("POST", 
                    config.base_url .. "/csv/import", 
                    json.encode(request_data))
                local end_time = os.clock() * 1000
                local latency = end_time - start_time
                
                thread_results.import_requests = thread_results.import_requests + 1
                thread_results.total_latency = thread_results.total_latency + latency
                
                if status == 200 then
                    thread_results.import_successes = thread_results.import_successes + 1
                    local result = json.decode(response)
                    if result and result.imported_count then
                        thread_results.imported_rows = thread_results.imported_rows + result.imported_count
                    end
                else
                    thread_results.import_failures = thread_results.import_failures + 1
                end
                
                os.remove(csv_filename)
            end
        else
            -- å¯¼å‡ºæ“ä½œ
            local business_type = config.business_types[math.random(1, #config.business_types)]
            local export_filename = "/tmp/csv_export_mixed_" .. business_type .. "_" .. os.time() .. "_" .. thread_id .. ".csv"
            
            local end_time = os.time() * 1000000
            local start_time = end_time - 3600 * 1000000
            
            local request_data = {
                file_path = export_filename,
                business_type = business_type,
                start_time = start_time,
                end_time = end_time,
                filters = {}
            }
            
            local start_time_ms = os.clock() * 1000
            local status, response = http_request("POST", 
                config.base_url .. "/csv/export", 
                json.encode(request_data))
            local end_time_ms = os.clock() * 1000
            local latency = end_time_ms - start_time_ms
            
            thread_results.export_requests = thread_results.export_requests + 1
            thread_results.total_latency = thread_results.total_latency + latency
            
            if status == 200 then
                thread_results.export_successes = thread_results.export_successes + 1
                local result = json.decode(response)
                if result and result.exported_count then
                    thread_results.exported_rows = thread_results.exported_rows + result.exported_count
                end
                
                os.remove(export_filename)
            else
                thread_results.export_failures = thread_results.export_failures + 1
            end
        end
        
        -- æ¯10ä¸ªè¯·æ±‚è¾“å‡ºä¸€æ¬¡è¿›åº¦
        if i % 10 == 0 then
            print(string.format("Thread %d: æ··åˆæµ‹è¯•è¿›åº¦ %d/%d (%.1f%%)", 
                thread_id, i, config.requests_per_thread, i/config.requests_per_thread*100))
        end
        
        -- æ·»åŠ éšæœºå»¶è¿Ÿ
        if math.random() < 0.25 then
            -- ç®€å•çš„å»¶è¿Ÿå®ç°ï¼Œæ›¿ä»£socket.sleep
            local delay = math.random() * 0.08
            local start_time = os.clock()
            while os.clock() - start_time < delay do
                -- å¿™ç­‰å¾…
            end
        end
    end
    
    return thread_results
end

-- ç»Ÿè®¡æ€§èƒ½æŒ‡æ ‡
local function calculate_performance_metrics(results)
    local metrics = {}
    
    -- è®¡ç®—æ€»è¯·æ±‚æ•°
    metrics.total_requests = results.total_requests
    metrics.success_rate = results.successful_requests / results.total_requests * 100
    metrics.error_rate = results.failed_requests / results.total_requests * 100
    
    -- è®¡ç®—å¹³å‡å»¶è¿Ÿ
    metrics.avg_latency = results.total_latency / results.total_requests
    
    -- è®¡ç®—ååé‡
    local test_duration = (results.end_time - results.start_time) / 1000  -- ç§’
    metrics.throughput = results.total_requests / test_duration
    
    -- è®¡ç®—P95å’ŒP99å»¶è¿Ÿ
    table.sort(results.latencies)
    local p95_index = math.floor(#results.latencies * 0.95)
    local p99_index = math.floor(#results.latencies * 0.99)
    metrics.p95_latency = results.latencies[p95_index] or 0
    metrics.p99_latency = results.latencies[p99_index] or 0
    
    return metrics
end

-- è¿è¡Œå‹åŠ›æµ‹è¯•
local function run_stress_test(test_type)
    print("=== CSVå¯¼å…¥å¯¼å‡ºå‹åŠ›æµ‹è¯•å¼€å§‹ ===")
    print("æµ‹è¯•ç±»å‹: " .. test_type)
    print("é…ç½®å‚æ•°:")
    print("  å¹¶å‘çº¿ç¨‹æ•°: " .. config.concurrent_threads)
    print("  æ¯ä¸ªçº¿ç¨‹è¯·æ±‚æ•°: " .. config.requests_per_thread)
    print("  æµ‹è¯•æŒç»­æ—¶é—´: " .. config.test_duration .. "ç§’")
    print("  é¢„çƒ­æ—¶é—´: " .. config.warmup_duration .. "ç§’")
    
    test_results.start_time = os.clock() * 1000
    
    -- é¢„çƒ­é˜¶æ®µ
    print("\n=== é¢„çƒ­é˜¶æ®µå¼€å§‹ ===")
    for i = 1, 3 do
        print("é¢„çƒ­è¯·æ±‚ " .. i)
        local business_type = config.business_types[math.random(1, #config.business_types)]
        local csv_filename = create_temp_csv_file(business_type, 10)
        
        if csv_filename then
            local request_data = {
                file_path = csv_filename,
                business_type = business_type,
                options = {batch_size = 10}
            }
            
            local status, response = http_request("POST", 
                config.base_url .. "/csv/import", 
                json.encode(request_data))
            
            os.remove(csv_filename)
            -- ç®€å•çš„å»¶è¿Ÿå®ç°ï¼Œæ›¿ä»£socket.sleep
            local start_time = os.clock()
            while os.clock() - start_time < 1 do
                -- å¿™ç­‰å¾…
            end
        end
    end
    print("=== é¢„çƒ­é˜¶æ®µå®Œæˆ ===\n")
    
    -- æ‰§è¡Œå‹åŠ›æµ‹è¯•
    local all_thread_results = {}
    
    for thread_id = 1, config.concurrent_threads do
        print("å¯åŠ¨çº¿ç¨‹ " .. thread_id)
        
        local thread_results
        if test_type == "import" then
            thread_results = csv_import_stress_test(thread_id)
        elseif test_type == "export" then
            thread_results = csv_export_stress_test(thread_id)
        else
            thread_results = mixed_stress_test(thread_id)
        end
        
        table.insert(all_thread_results, thread_results)
        
        -- æ±‡æ€»çº¿ç¨‹ç»“æœ
        if test_type == "import" then
            test_results.total_requests = test_results.total_requests + thread_results.requests
            test_results.successful_requests = test_results.successful_requests + thread_results.successes
            test_results.failed_requests = test_results.failed_requests + thread_results.failures
            test_results.total_latency = test_results.total_latency + thread_results.total_latency
            test_results.csv_import_stats.imported_rows = (test_results.csv_import_stats.imported_rows or 0) + thread_results.imported_rows
        elseif test_type == "export" then
            test_results.total_requests = test_results.total_requests + thread_results.requests
            test_results.successful_requests = test_results.successful_requests + thread_results.successes
            test_results.failed_requests = test_results.failed_requests + thread_results.failures
            test_results.total_latency = test_results.total_latency + thread_results.total_latency
            test_results.csv_export_stats.exported_rows = (test_results.csv_export_stats.exported_rows or 0) + thread_results.exported_rows
        else
            test_results.total_requests = test_results.total_requests + thread_results.import_requests + thread_results.export_requests
            test_results.successful_requests = test_results.successful_requests + thread_results.import_successes + thread_results.export_successes
            test_results.failed_requests = test_results.failed_requests + thread_results.import_failures + thread_results.export_failures
            test_results.total_latency = test_results.total_latency + thread_results.total_latency
            test_results.csv_import_stats.imported_rows = (test_results.csv_import_stats.imported_rows or 0) + thread_results.imported_rows
            test_results.csv_export_stats.exported_rows = (test_results.csv_export_stats.exported_rows or 0) + thread_results.exported_rows
        end
    end
    
    test_results.end_time = os.clock() * 1000
    
    -- è®¡ç®—æ€§èƒ½æŒ‡æ ‡
    local metrics = calculate_performance_metrics(test_results)
    
    -- è¾“å‡ºæµ‹è¯•ç»“æœ
    print("\n=== CSVå¯¼å…¥å¯¼å‡ºå‹åŠ›æµ‹è¯•ç»“æœ ===")
    print("æµ‹è¯•ç±»å‹: " .. test_type)
    print("æ€»è¯·æ±‚æ•°: " .. test_results.total_requests)
    print("æˆåŠŸè¯·æ±‚æ•°: " .. test_results.successful_requests)
    print("å¤±è´¥è¯·æ±‚æ•°: " .. test_results.failed_requests)
    print("æˆåŠŸç‡: " .. string.format("%.2f%%", metrics.success_rate))
    print("é”™è¯¯ç‡: " .. string.format("%.2f%%", metrics.error_rate))
    print("å¹³å‡å»¶è¿Ÿ: " .. string.format("%.2fms", metrics.avg_latency))
    print("P95å»¶è¿Ÿ: " .. string.format("%.2fms", metrics.p95_latency))
    print("P99å»¶è¿Ÿ: " .. string.format("%.2fms", metrics.p99_latency))
    print("ååé‡: " .. string.format("%.2f è¯·æ±‚/ç§’", metrics.throughput))
    
    if test_results.csv_import_stats.imported_rows then
        print("å¯¼å…¥æ•°æ®è¡Œæ•°: " .. test_results.csv_import_stats.imported_rows)
    end
    
    if test_results.csv_export_stats.exported_rows then
        print("å¯¼å‡ºæ•°æ®è¡Œæ•°: " .. test_results.csv_export_stats.exported_rows)
    end
    
    -- æ£€æŸ¥æ€§èƒ½é˜ˆå€¼
    print("\n=== æ€§èƒ½é˜ˆå€¼æ£€æŸ¥ ===")
    local all_passed = true
    
    if metrics.p99_latency > config.max_latency_p99 then
        print("âŒ P99å»¶è¿Ÿè¶…æ ‡: " .. string.format("%.2fms > %.2fms", metrics.p99_latency, config.max_latency_p99))
        all_passed = false
    else
        print("âœ… P99å»¶è¿Ÿæ­£å¸¸: " .. string.format("%.2fms <= %.2fms", metrics.p99_latency, config.max_latency_p99))
    end
    
    if metrics.throughput < config.min_throughput then
        print("âŒ ååé‡ä¸è¶³: " .. string.format("%.2f < %.2f", metrics.throughput, config.min_throughput))
        all_passed = false
    else
        print("âœ… ååé‡æ­£å¸¸: " .. string.format("%.2f >= %.2f", metrics.throughput, config.min_throughput))
    end
    
    if metrics.error_rate > config.max_error_rate * 100 then
        print("âŒ é”™è¯¯ç‡è¶…æ ‡: " .. string.format("%.2f%% > %.2f%%", metrics.error_rate, config.max_error_rate * 100))
        all_passed = false
    else
        print("âœ… é”™è¯¯ç‡æ­£å¸¸: " .. string.format("%.2f%% <= %.2f%%", metrics.error_rate, config.max_error_rate * 100))
    end
    
    if all_passed then
        print("\nğŸ‰ æ‰€æœ‰æ€§èƒ½æŒ‡æ ‡å‡ç¬¦åˆè¦æ±‚ï¼")
    else
        print("\nâš ï¸  éƒ¨åˆ†æ€§èƒ½æŒ‡æ ‡æœªè¾¾åˆ°è¦æ±‚ï¼Œéœ€è¦ä¼˜åŒ–ï¼")
    end
    
    return all_passed
end

-- ä¸»å‡½æ•°
local function main(...)
    local args = {...}
    local test_type = args[1] or "mixed"  -- é»˜è®¤æ··åˆæµ‹è¯•
    
    if test_type ~= "import" and test_type ~= "export" and test_type ~= "mixed" then
        print("ç”¨æ³•: luajit csv-stress-test.lua [import|export|mixed]")
        print("  import - ä»…æµ‹è¯•CSVå¯¼å…¥")
        print("  export - ä»…æµ‹è¯•CSVå¯¼å‡º") 
        print("  mixed  - æ··åˆæµ‹è¯•å¯¼å…¥å’Œå¯¼å‡ºï¼ˆé»˜è®¤ï¼‰")
        return
    end
    
    print("Stock-TSDB CSVå¯¼å…¥å¯¼å‡ºå‹åŠ›æµ‹è¯•")
    print("å¼€å§‹æ—¶é—´: " .. os.date("%Y-%m-%d %H:%M:%S"))
    
    local success = run_stress_test(test_type)
    
    print("\nç»“æŸæ—¶é—´: " .. os.date("%Y-%m-%d %H:%M:%S"))
    
    if success then
        os.exit(0)
    else
        os.exit(1)
    end
end

-- è¿è¡Œä¸»å‡½æ•°
main(...)