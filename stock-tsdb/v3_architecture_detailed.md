# V3å­˜å‚¨å¼•æ“è¯¦ç»†æ¶æ„è¯´æ˜

## ğŸ—ï¸ æ•´ä½“æ¶æ„æ¦‚è¿°

V3å­˜å‚¨å¼•æ“é‡‡ç”¨æ’ä»¶åŒ–æ¶æ„è®¾è®¡ï¼Œæ”¯æŒåŸºç¡€ç‰ˆæœ¬å’Œé›†æˆç‰ˆæœ¬ä¸¤ç§å®ç°ï¼Œæä¾›ç»Ÿä¸€çš„APIæ¥å£ã€‚æ•´ä¸ªç³»ç»Ÿé‡‡ç”¨åˆ†å±‚æ¶æ„ï¼Œä»åº”ç”¨å±‚åˆ°å­˜å‚¨å±‚éƒ½æœ‰æ¸…æ™°çš„èŒè´£åˆ’åˆ†ã€‚

### æ¶æ„å±‚æ¬¡

```
åº”ç”¨å±‚ (Application Layer)
    â†“
APIå±‚ (API Layer) 
    â†“
å¼•æ“å±‚ (Engine Layer)
    â†“
å­˜å‚¨å±‚ (Storage Layer)
    â†“
åŸºç¡€è®¾æ–½å±‚ (Infrastructure Layer)
```

## ğŸ”§ æ ¸å¿ƒç»„ä»¶è¯¦ç»†è¯´æ˜

### 1. V3StorageEngine æ ¸å¿ƒç±»

```lua
-- æ ¸å¿ƒç±»ç»“æ„
V3StorageEngine = {
    config = {},           -- é…ç½®å‚æ•°
    data = {},             -- å†…å­˜æ•°æ®å­˜å‚¨
    initialized = false,   -- åˆå§‹åŒ–çŠ¶æ€
    csv_manager = nil,     -- CSVæ•°æ®ç®¡ç†å™¨
    
    -- å†·çƒ­æ•°æ®åˆ†ç¦»é…ç½®
    enable_cold_data_separation = false,
    cold_data_threshold_days = 30
}
```

#### ä¸»è¦æ–¹æ³•

**åˆå§‹åŒ–æ–¹æ³•**
- `new(config)`: åˆ›å»ºå¼•æ“å®ä¾‹
- `initialize()`: åˆå§‹åŒ–å¼•æ“
- `close()`: å…³é—­å¼•æ“

**æ•°æ®æ“ä½œæ–¹æ³•**
- `write_point(metric, timestamp, value, tags)`: å†™å…¥æ•°æ®ç‚¹
- `read_point(metric, start_time, end_time, tags)`: æŸ¥è¯¢æ•°æ®ç‚¹
- `encode_metric_key(metric, timestamp, tags)`: RowKeyç¼–ç 
- `encode_stock_key(stock_code, timestamp, market)`: è‚¡ç¥¨æ•°æ®ç¼–ç 

**ç®¡ç†æ–¹æ³•**
- `get_cf_name_for_timestamp(timestamp)`: ColumnFamilyç®¡ç†
- `get_stats()`: è·å–ç»Ÿè®¡ä¿¡æ¯
- `migrate_to_cold_data(timestamp)`: å†·æ•°æ®è¿ç§»
- `cleanup_old_data(retention_days)`: æ•°æ®æ¸…ç†

### 2. æ•°æ®å­˜å‚¨æ¶æ„

#### RowKeyç¼–ç ç­–ç•¥

```lua
-- é€šç”¨æ•°æ®ç¼–ç 
function encode_metric_key(metric, timestamp, tags)
    -- æ ¼å¼: metric_tag1=value1_tag2=value2
    local key_parts = {metric}
    if tags then
        for k, v in pairs(tags) do
            table.insert(key_parts, string.format("%s=%s", k, v))
        end
    end
    return table.concat(key_parts, "_"), string.format("%08x", timestamp % 0x100000000)
end

-- è‚¡ç¥¨æ•°æ®ç¼–ç 
function encode_stock_key(stock_code, timestamp, market)
    -- æ ¼å¼: stock_code_market
    return string.format("stock_%s_%s", stock_code, market), 
           string.format("%08x", timestamp % 0x100000000)
end
```

#### 30ç§’å®šé•¿å—å­˜å‚¨

```lua
-- å—æ—¶é—´è®¡ç®—
function calculate_block_time(timestamp)
    return math.floor(timestamp / 30) * 30  -- 30ç§’å¯¹é½
end

-- å—å†…åç§»
function calculate_block_offset(timestamp)
    return timestamp % 30  -- 0-29ç§’åç§»
end
```

### 3. å†·çƒ­æ•°æ®åˆ†ç¦»æœºåˆ¶

#### æ•°æ®åˆ†ç±»ç­–ç•¥

```lua
function get_cf_name_for_timestamp(timestamp)
    local date = os.date("*t", timestamp)
    local date_str = string.format("%04d%02d%02d", date.year, date.month, date.day)
    
    if self.enable_cold_data_separation then
        local current_time = os.time()
        local days_diff = os.difftime(current_time, timestamp) / (24 * 60 * 60)
        
        if days_diff > self.cold_data_threshold_days then
            return "cold_" .. date_str  -- å†·æ•°æ®ColumnFamily
        else
            return "cf_" .. date_str    -- çƒ­æ•°æ®ColumnFamily
        end
    else
        return "cf_" .. date_str       -- ç»Ÿä¸€ColumnFamily
    end
end
```

#### å†·çƒ­æ•°æ®ç»Ÿè®¡

```lua
function get_cold_hot_stats()
    local current_time = os.time()
    local hot_count, cold_count = 0, 0
    
    for key, data in pairs(self.data) do
        local days_diff = os.difftime(current_time, data.timestamp) / (24 * 60 * 60)
        if days_diff <= self.cold_data_threshold_days then
            hot_count = hot_count + 1
        else
            cold_count = cold_count + 1
        end
    end
    
    return {hot = hot_count, cold = cold_count}
end
```

## ğŸ”„ æ•°æ®æµç¨‹è¯¦ç»†è¯´æ˜

### 1. æ•°æ®å†™å…¥æµç¨‹

#### æ­¥éª¤åˆ†è§£

1. **æ•°æ®æ¥æ”¶ä¸éªŒè¯**
   ```lua
   -- éªŒè¯æ•°æ®æ ¼å¼
   if not metric or not timestamp or not value then
       return false, "ç¼ºå°‘å¿…è¦å‚æ•°"
   end
   
   -- éªŒè¯æ—¶é—´æˆ³æœ‰æ•ˆæ€§
   if timestamp <= 0 then
       return false, "æ—¶é—´æˆ³æ— æ•ˆ"
   end
   ```

2. **RowKeyç¼–ç **
   ```lua
   -- ç”ŸæˆRowKeyå’ŒQualifier
   local row_key, qualifier = self:encode_metric_key(metric, timestamp, tags)
   ```

3. **å†·çƒ­æ•°æ®åˆ¤æ–­**
   ```lua
   -- ç¡®å®šå­˜å‚¨çš„ColumnFamily
   local cf_name = self:get_cf_name_for_timestamp(timestamp)
   ```

4. **æ•°æ®å­˜å‚¨**
   ```lua
   -- å­˜å‚¨åˆ°å†…å­˜æ•°æ®ç»“æ„
   local key = string.format("%s_%d", metric, timestamp)
   self.data[key] = {
       metric = metric,
       timestamp = timestamp,
       value = value,
       tags = tags
   }
   ```

### 2. æ•°æ®æŸ¥è¯¢æµç¨‹

#### æ­¥éª¤åˆ†è§£

1. **æŸ¥è¯¢è§£æ**
   ```lua
   -- è§£ææŸ¥è¯¢å‚æ•°
   local start_ts = start_time or 0
   local end_ts = end_time or os.time()
   ```

2. **æ—¶é—´èŒƒå›´ä¼˜åŒ–**
   ```lua
   -- ç¡®å®šéœ€è¦æŸ¥è¯¢çš„ColumnFamilyèŒƒå›´
   local start_cf = self:get_cf_name_for_timestamp(start_ts)
   local end_cf = self:get_cf_name_for_timestamp(end_ts)
   ```

3. **æ•°æ®æ£€ç´¢**
   ```lua
   -- éå†å†…å­˜æ•°æ®ç»“æ„
   local results = {}
   for key, data in pairs(self.data) do
       if data.metric == metric and 
          data.timestamp >= start_ts and 
          data.timestamp <= end_ts then
           table.insert(results, data)
       end
   end
   ```

4. **ç»“æœå¤„ç†**
   ```lua
   -- æ’åºå’Œæ ¼å¼åŒ–ç»“æœ
   table.sort(results, function(a, b) return a.timestamp < b.timestamp end)
   return true, results
   ```

## ğŸ¢ V3é›†æˆç‰ˆæœ¬æ¶æ„

### 1. é›†ç¾¤æ¶æ„è®¾è®¡

#### ä¸€è‡´æ€§å“ˆå¸Œåˆ†ç‰‡

```lua
-- è™šæ‹ŸèŠ‚ç‚¹ç®¡ç†
function create_virtual_nodes(physical_nodes, virtual_nodes_per_physical)
    local virtual_nodes = {}
    for _, node in ipairs(physical_nodes) do
        for i = 1, virtual_nodes_per_physical do
            local virtual_node = string.format("%s_virtual_%d", node, i)
            table.insert(virtual_nodes, {
                physical_node = node,
                virtual_node = virtual_node,
                hash = hash_function(virtual_node)
            })
        end
    end
    return virtual_nodes
end

-- æ•°æ®è·¯ç”±
function route_data(key, virtual_nodes)
    local key_hash = hash_function(key)
    -- åœ¨å“ˆå¸Œç¯ä¸Šæ‰¾åˆ°åˆé€‚çš„èŠ‚ç‚¹
    -- ...
end
```

#### ZeroMQé›†ç¾¤é€šä¿¡

```lua
-- æ¶ˆæ¯æ ¼å¼å®šä¹‰
local message_types = {
    DATA_WRITE = 1,
    DATA_READ = 2,
    HEARTBEAT = 3,
    SYNC_REQUEST = 4,
    SYNC_RESPONSE = 5
}

-- æ¶ˆæ¯å¤„ç†
function handle_zmq_message(message)
    local msg_type = message.type
    
    if msg_type == message_types.DATA_WRITE then
        return handle_data_write(message)
    elseif msg_type == message_types.DATA_READ then
        return handle_data_read(message)
    -- ... å…¶ä»–æ¶ˆæ¯ç±»å‹
    end
end
```

### 2. é«˜å¯ç”¨æœºåˆ¶

#### ConsulæœåŠ¡å‘ç°

```lua
-- æœåŠ¡æ³¨å†Œ
function register_with_consul(service_config)
    local consul = require("consul")
    local client = consul:new(service_config.consul_endpoints)
    
    return client:register_service({
        ID = service_config.node_id,
        Name = service_config.cluster_name,
        Address = service_config.node_address,
        Port = service_config.service_port,
        Check = {
            HTTP = service_config.health_check_url,
            Interval = "10s",
            Timeout = "5s"
        }
    })
end
```

#### æ•…éšœæ£€æµ‹ä¸æ¢å¤

```lua
-- å¥åº·æ£€æŸ¥
function health_check()
    return {
        status = "healthy",
        timestamp = os.time(),
        memory_usage = collectgarbage("count"),
        data_points = #self.data,
        last_heartbeat = self.last_heartbeat_time
    }
end

-- æ•…éšœè½¬ç§»
function handle_node_failure(failed_node)
    -- é‡æ–°åˆ†é…æ•°æ®
    -- æ›´æ–°è·¯ç”±è¡¨
    -- é€šçŸ¥å®¢æˆ·ç«¯
end
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–æŠ€æœ¯

### 1. å­˜å‚¨ä¼˜åŒ–

#### å‹ç¼©ç®—æ³•é€‰æ‹©

```lua
-- å‹ç¼©é…ç½®
local compression_algorithms = {
    lz4 = {
        name = "lz4",
        level = 1,
        enabled = true
    },
    snappy = {
        name = "snappy", 
        level = 1,
        enabled = false
    }
}

function configure_compression(algorithm_config)
    if algorithm_config.enabled then
        rocksdb_options_set_compression(self.options, algorithm_config.name)
        rocksdb_options_set_compression_level(self.options, algorithm_config.level)
    end
end
```

#### ç¼“å­˜ç­–ç•¥

```lua
-- å—ç¼“å­˜é…ç½®
function configure_block_cache(cache_size_mb)
    local cache = rocksdb_cache_create_lru(cache_size_mb * 1024 * 1024)
    rocksdb_options_set_block_cache(self.options, cache)
end

-- å†™å…¥ç¼“å†²åŒº
function configure_write_buffer(write_buffer_size_mb, max_write_buffers)
    rocksdb_options_set_write_buffer_size(self.options, write_buffer_size_mb * 1024 * 1024)
    rocksdb_options_set_max_write_buffer_number(self.options, max_write_buffers)
end
```

### 2. æŸ¥è¯¢ä¼˜åŒ–

#### å¹¶è¡ŒæŸ¥è¯¢

```lua
-- å¤šçº¿ç¨‹æŸ¥è¯¢
function parallel_query(queries, num_threads)
    local threads = {}
    local results = {}
    
    -- åˆ†å‰²æŸ¥è¯¢ä»»åŠ¡
    local query_chunks = split_queries(queries, num_threads)
    
    for i, chunk in ipairs(query_chunks) do
        threads[i] = coroutine.create(function()
            return execute_queries(chunk)
        end)
    end
    
    -- ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
    for i, thread in ipairs(threads) do
        local success, result = coroutine.resume(thread)
        if success then
            table.insert(results, result)
        end
    end
    
    return merge_results(results)
end
```

#### ç´¢å¼•ä¼˜åŒ–

```lua
-- å‰ç¼€å‹ç¼©
function configure_prefix_extractor()
    local prefix_extractor = rocksdb_slice_transform_create_fixed_prefix(8)  -- 8å­—èŠ‚å‰ç¼€
    rocksdb_options_set_prefix_extractor(self.options, prefix_extractor)
end

-- å¸ƒéš†è¿‡æ»¤å™¨
function configure_bloom_filter(bits_per_key)
    local filter = rocksdb_filterpolicy_create_bloom(bits_per_key)
    rocksdb_options_set_filter_policy(self.options, filter)
end
```

## ğŸ”§ ç›‘æ§ä¸è¿ç»´

### 1. ç»Ÿè®¡ä¿¡æ¯æ”¶é›†

```lua
function collect_detailed_stats()
    return {
        -- åŸºç¡€ä¿¡æ¯
        is_initialized = self.initialized,
        uptime = os.time() - self.start_time,
        
        -- æ•°æ®ç»Ÿè®¡
        total_data_points = #self.data,
        hot_data_points = self:get_cold_hot_stats().hot,
        cold_data_points = self:get_cold_hot_stats().cold,
        
        -- æ€§èƒ½ç»Ÿè®¡
        write_operations = self.stats.write_count or 0,
        read_operations = self.stats.read_count or 0,
        average_write_latency = self.stats.avg_write_latency or 0,
        average_read_latency = self.stats.avg_read_latency or 0,
        
        -- èµ„æºä½¿ç”¨
        memory_usage = collectgarbage("count") * 1024,  -- bytes
        file_descriptors = get_open_file_descriptors(),
        
        -- é›†ç¾¤ä¿¡æ¯ï¼ˆé›†æˆç‰ˆæœ¬ï¼‰
        cluster_enabled = self.cluster_enabled or false,
        cluster_nodes = self.cluster_nodes or {},
        replication_factor = self.replication_factor or 1
    }
end
```

### 2. å¥åº·æ£€æŸ¥

```lua
function perform_health_check()
    local checks = {
        {name = "å¼•æ“çŠ¶æ€", check = function() return self.initialized end},
        {name = "å†…å­˜ä½¿ç”¨", check = function() return collectgarbage("count") < 1000 end},  -- < 1GB
        {name = "æ•°æ®å®Œæ•´æ€§", check = function() return self:verify_data_integrity() end},
        {name = "å­˜å‚¨å¯ç”¨æ€§", check = function() return self:check_storage_availability() end}
    }
    
    local results = {}
    for _, check in ipairs(checks) do
        local success, err = pcall(check.check)
        results[check.name] = {
            status = success and "healthy" or "unhealthy",
            error = err
        }
    end
    
    return results
end
```

## ğŸ“ˆ éƒ¨ç½²æ¶æ„

### 1. å•æœºéƒ¨ç½²é…ç½®

```lua
-- åŸºç¡€ç‰ˆæœ¬é…ç½®
local basic_config = {
    data_dir = "./data/basic",
    block_size = 30,
    enable_compression = true,
    compression_type = "lz4",
    write_buffer_size = 64 * 1024 * 1024,  -- 64MB
    max_write_buffer_number = 4,
    target_file_size_base = 64 * 1024 * 1024,
    max_bytes_for_level_base = 256 * 1024 * 1024
}
```

### 2. é›†ç¾¤éƒ¨ç½²é…ç½®

```lua
-- é›†æˆç‰ˆæœ¬é…ç½®
local integrated_config = {
    data_dir = "./data/integrated",
    node_id = "node_1",
    cluster_name = "tsdb-cluster",
    
    -- å­˜å‚¨é…ç½®
    block_size = 30,
    enable_compression = true,
    compression_type = "lz4",
    
    -- é›†ç¾¤é…ç½®
    seed_nodes = {"node1:9090", "node2:9090", "node3:9090"},
    gossip_port = 9090,
    data_port = 9091,
    consul_endpoints = {"http://127.0.0.1:8500"},
    replication_factor = 3,
    virtual_nodes_per_physical = 100,
    
    -- é«˜å¯ç”¨é…ç½®
    enable_ha = true,
    heartbeat_interval = 5,  -- 5ç§’
    failure_detection_timeout = 30  -- 30ç§’
}
```

## ğŸ¯ æ€»ç»“

V3å­˜å‚¨å¼•æ“é€šè¿‡æ’ä»¶åŒ–æ¶æ„è®¾è®¡ï¼Œæä¾›äº†çµæ´»ä¸”é«˜æ€§èƒ½çš„æ—¶é—´åºåˆ—æ•°æ®å­˜å‚¨è§£å†³æ–¹æ¡ˆã€‚åŸºç¡€ç‰ˆæœ¬é€‚åˆå•æœºéƒ¨ç½²åœºæ™¯ï¼Œé›†æˆç‰ˆæœ¬åˆ™æä¾›äº†å®Œæ•´çš„åˆ†å¸ƒå¼é›†ç¾¤åŠŸèƒ½ã€‚æ•´ä¸ªç³»ç»Ÿåœ¨è®¾è®¡ä¸Šè€ƒè™‘äº†æ€§èƒ½ã€å¯é æ€§å’Œå¯æ‰©å±•æ€§ï¼Œä¸ºä¸åŒè§„æ¨¡çš„ä¸šåŠ¡éœ€æ±‚æä¾›äº†åˆé€‚çš„è§£å†³æ–¹æ¡ˆã€‚

å…³é”®ç‰¹æ€§æ€»ç»“ï¼š
- âœ… æ’ä»¶åŒ–æ¶æ„ï¼Œæ”¯æŒå¤šç§å­˜å‚¨å¼•æ“å®ç°
- âœ… 30ç§’å®šé•¿å—å­˜å‚¨ï¼Œä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½
- âœ… å†·çƒ­æ•°æ®åˆ†ç¦»ï¼Œé™ä½å­˜å‚¨æˆæœ¬
- âœ… ä¸€è‡´æ€§å“ˆå¸Œåˆ†ç‰‡ï¼Œæ”¯æŒæ°´å¹³æ‰©å±•
- âœ… å®Œå–„çš„ç›‘æ§å’Œè¿ç»´æ”¯æŒ
- âœ… ä¸°å¯Œçš„æ€§èƒ½ä¼˜åŒ–é€‰é¡¹